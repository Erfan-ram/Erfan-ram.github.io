<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Audio2Text - Erfan Ramezani</title>

  <link rel="icon" href="../assets/images/erfan-avatar-circle.png" type="image/png">
  <link rel="apple-touch-icon" href="../assets/images/erfan-avatar-circle.png">
  <link rel="stylesheet" href="../assets/css/style.css">
  <link rel="stylesheet" href="../assets/css/project-style.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">
</head>

<body>

  <main>

    <div class="main-content">

      <nav class="navbar">
        <ul class="navbar-list">
          <li class="navbar-item">
            <a href="../index.html#portfolio" class="navbar-link">‚Üê Back to Portfolio</a>
          </li>
        </ul>
      </nav>

      <article class="project-detail active" data-page="project-detail">

        <header>
          <h2 class="h2 article-title">Audio2Text - Speech Recognition System</h2>
        </header>

        <section class="project-info">
          
          <img src="../assets/images/project-9.png" alt="Audio2Text System" class="project-image">
          
          <div class="project-meta">
            <p><strong>Category:</strong> AI/ML</p>
            <p><strong>Technologies:</strong> Python, Speech Recognition, Deep Learning, NLP</p>
            <p><strong>GitHub:</strong> Private Repository</p>
            <p><strong>Status:</strong> Completed</p>
          </div>

          <div class="project-overview">
            <h3 class="h3">Project Overview</h3>
            <p>
              Audio2Text is an advanced speech recognition system that converts spoken language into written text with 
              high accuracy. The project leverages state-of-the-art deep learning models to transcribe audio recordings, 
              supporting multiple audio formats and handling various acoustic conditions.
            </p>
            <p>
              The system is designed for applications such as automated transcription services, voice-controlled interfaces, 
              meeting minutes generation, and accessibility tools for hearing-impaired users. It implements noise reduction 
              and speaker diarization to improve transcription quality in challenging audio environments.
            </p>
          </div>

          <div class="project-features">
            <h3 class="h3">Key Features</h3>
            <ul>
              <li>High-accuracy speech-to-text conversion</li>
              <li>Support for multiple audio formats (WAV, MP3, FLAC)</li>
              <li>Real-time and batch processing modes</li>
              <li>Noise reduction and audio preprocessing</li>
              <li>Speaker diarization (identifying different speakers)</li>
              <li>Timestamp generation for transcriptions</li>
              <li>Multi-language support capability</li>
            </ul>
          </div>

          <div class="project-tech-stack">
            <h3 class="h3">Technology Stack</h3>
            <div class="tech-grid">
              <div class="tech-item">
                <h4>Python</h4>
                <p>Primary programming language for audio processing and model implementation</p>
              </div>
              <div class="tech-item">
                <h4>Deep Learning Models</h4>
                <p>Advanced neural networks for speech recognition, including transformers and RNNs</p>
              </div>
              <div class="tech-item">
                <h4>Audio Processing Libraries</h4>
                <p>Tools like Librosa and PyDub for audio manipulation and feature extraction</p>
              </div>
            </div>
          </div>

          <div class="project-results">
            <h3 class="h3">Results & Impact</h3>
            <p>
              Audio2Text achieves excellent transcription accuracy across various audio qualities and acoustic conditions. 
              The system significantly reduces the time required for manual transcription, making it valuable for 
              journalists, researchers, and content creators. Its robust performance in noisy environments makes it 
              suitable for real-world applications.
            </p>
          </div>

          <div class="project-future">
            <h3 class="h3">Future Enhancements</h3>
            <ul>
              <li>Enhanced support for accents and dialects</li>
              <li>Real-time streaming transcription</li>
              <li>Integration with popular video conferencing platforms</li>
              <li>Custom vocabulary and domain adaptation</li>
              <li>Automated punctuation and formatting</li>
            </ul>
          </div>

          <div class="project-gallery">
            <h3 class="h3">Project Gallery</h3>
            <div class="gallery-grid">
              <img src="../assets/images/projects/audio2text/screenshot1.jpg" alt="Audio2Text Screenshot 1" class="gallery-image">
              <img src="../assets/images/projects/audio2text/screenshot2.jpg" alt="Audio2Text Screenshot 2" class="gallery-image">
              <img src="../assets/images/projects/audio2text/screenshot3.jpg" alt="Audio2Text Screenshot 3" class="gallery-image">
            </div>
          </div>

        </section>

      </article>

    </div>

  </main>

  <script src="../assets/js/script.js"></script>
  <script src="../assets/js/lightbox.js"></script>
  <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>

</body>

</html>
